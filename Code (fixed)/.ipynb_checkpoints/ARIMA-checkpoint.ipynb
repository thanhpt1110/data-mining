{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b9a87b-481a-46be-9e4b-16efff0aaa67",
   "metadata": {},
   "source": [
    "# ARIMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09284e32-99de-45bd-90d4-c1a928201e26",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e571418-dad2-4a22-957f-4ea11bb43748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5b1dd-1510-46ca-99c4-587dc6bdd023",
   "metadata": {},
   "source": [
    "## 2. Đọc Dataset và chia data thành 2 bộ train và test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862caf73-ccdb-45a9-bb55-9e11242c7b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/gld_price_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Đọc dữ liệu từ file CSV, lấy các cột cần thiết và phân tích cột 'Date' làm chỉ mục\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/gld_price_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEUR/USD\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# df.sort_values(by='Date', ascending=True, inplace=True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# df.reset_index(inplace=True)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Loại bỏ các dòng có giá trị thiếu (NaN) trong dữ liệu\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab-data-mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab-data-mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab-data-mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab-data-mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab-data-mining\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/gld_price_data.csv'"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file CSV, lấy các cột cần thiết và phân tích cột 'Date' làm chỉ mục\n",
    "df = pd.read_csv('../Data/gld_price_data.csv', index_col='Date', parse_dates=True, usecols=['Date', 'SPX', 'GLD', 'USO', 'SLV', 'EUR/USD'])\n",
    "# df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "# df.reset_index(inplace=True)\n",
    "\n",
    "# Loại bỏ các dòng có giá trị thiếu (NaN) trong dữ liệu\n",
    "df = df.dropna()\n",
    "\n",
    "# Tách dữ liệu thành train_data và test_data theo tỉ lệ 80:20\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# In kích thước của tập dữ liệu huấn luyện\n",
    "print('Shape of data train', train_data.shape)\n",
    "\n",
    "# In kích thước của tập dữ liệu kiểm tra\n",
    "print('Shape of data test', test_data.shape)\n",
    "\n",
    "# Tách biến mục tiêu 'GLD' từ tập dữ liệu huấn luyện\n",
    "y_train = train_data['GLD']\n",
    "y_test = test_data['GLD']\n",
    "\n",
    "# Tách các biến đầu vào (features) từ tập dữ liệu huấn luyện, loại bỏ cột 'GLD'\n",
    "X_train = train_data.drop(columns=['GLD'])\n",
    "X_test = test_data.drop(columns=['GLD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae1d24-4936-412f-971b-7d10f9013bd6",
   "metadata": {},
   "source": [
    "## 3. Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b3e11-6807-40a6-977d-a74d2b29e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập kích thước biểu đồ với chiều rộng full (ví dụ 15 inch)\n",
    "plt.figure(figsize=(15, 6), dpi=150)\n",
    "\n",
    "# Vẽ biểu đồ cho tập huấn luyện (train)\n",
    "plt.plot(train_data['GLD'], label='Train Data')\n",
    "\n",
    "# Vẽ biểu đồ cho tập kiểm tra (test)\n",
    "plt.plot(test_data['GLD'], label='Test Data')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.title('Gold Price - Train & Test Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Gold Price')\n",
    "\n",
    "# Chú thích\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.grid(color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf67303-9ad8-4fdd-89c1-55daafbbfb45",
   "metadata": {},
   "source": [
    "## 4. Thông tin chi tiết của tập Train và Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744ac82-c905-4cfd-bfe4-d5e2a85e420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18579e12-79dc-4a9b-8d27-61a655e64926",
   "metadata": {},
   "source": [
    "### 5. Kiểm tra chuỗi thời gian có phải chuỗi dừng hay không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cb935-5ba5-4764-b8c6-2c71261a5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def check_adfuller(datasset):\n",
    "  result = adfuller(datasset, autolag='AIC')\n",
    "  print(\"1. ADF\", result[0])\n",
    "  print(\"2. P-Value: \", result[1])\n",
    "  print(\"3. Num of Lags: \", result[2])\n",
    "  print(\"4. Num of Observations Used for ADF Regression and Critical values calculation: \", result[3])\n",
    "  print(\"5. Critical values: \")\n",
    "  for key, val in result[4].items():\n",
    "    print(\"\\t\", key, \": \", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e2e53-2cb3-4e50-8710-58e38a387660",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_adfuller(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32496beb-4172-4522-8032-80f2abec6795",
   "metadata": {},
   "source": [
    "**Giải thích kết quả:**\n",
    "\n",
    "Kết quả kiểm định Dickey-Fuller tăng cường (ADF) cho chuỗi thời gian giá vàng cho thấy:\n",
    "1.   Giá trị thống kê ADF (-1.70575) không đủ âm để bác bỏ giả thuyết null về sự tồn tại của gốc đơn vị, cho thấy chuỗi có khả năng không dừng.\n",
    "2.   P-Value (0.4281) cao hơn mức ngưỡng thông thường (0.05), không đủ để bác bỏ giả thuyết null, hỗ trợ kết luận chuỗi không dừng.\n",
    "3.   Số độ trễ là 1 và số lượng quan sát là 1830 được sử dụng trong phân tích.\n",
    "4.   Các giá trị tới hạn cho 1%, 5%, và 10% đều nhỏ hơn giá trị thống kê ADF, củng cố thêm bằng chứng rằng chuỗi không dừng.\n",
    "\n",
    "**Kết luận:** Chuỗi thời gian giá vàng không dừng. Cần biến đổi chuỗi (ví dụ: lấy sai phân) trước khi áp dụng mô hình dự báo như ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0eba2-707c-4eec-83cb-65607cbcf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_diff = y_train.diff().dropna()\n",
    "\n",
    "# Hiển thị vài dòng đầu của chuỗi đã biến đổi\n",
    "print(y_train_diff.head())\n",
    "\n",
    "# Kiểm tra tính dừng của chuỗi đã biến đổi\n",
    "check_adfuller(y_train_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce14a49-3f00-4b96-93f3-67cfd22534e5",
   "metadata": {},
   "source": [
    "**Giải thích kết quả:**\n",
    "\n",
    "Kết quả kiểm định Dickey-Fuller tăng cường (ADF) cho chuỗi thời gian giá vàng cho thấy:\n",
    "1.   Giá trị thống kê ADF (-44.50652871715483) rất âm và thấp hơn các giá trị tới hạn cho mọi mức ý nghĩa thống kê (1%, 5%, 10%), cho thấy chuỗi đã dừng.\n",
    "2.   P-Value (0.0) rất nhỏ, cung cấp bằng chứng mạnh mẽ để bác bỏ giả thuyết null, khẳng định chuỗi đã dừng.\n",
    "3.   Số độ trễ là 0 và số lượng quan sát là 1830 được sử dụng trong phân tích.\n",
    "\n",
    "**Kết luận:** Chuỗi sai phân đã dừng, cho phép tiếp tục mô hình hóa và dự báo sử dụng mô hình ARIMA hoặc các mô hình chuỗi thời gian khác. Chuỗi đã dừng là điều kiện cần thiết cho việc mô hình hóa chuỗi thời gian hiệu quả."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b22664-0396-490d-aae2-7c3e7423b7e8",
   "metadata": {},
   "source": [
    "### 6. Chọn mô hình phù hợp nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b66d6-101f-43d9-a314-9cebb8c603d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "stepwise_fit = auto_arima(y_train_diff, start_p=0, start_q=0,\n",
    "                      test='adf',       # sử dụng ADF test để xác định d\n",
    "                      max_p=5, max_q=5, # giới hạn tối đa cho p và q\n",
    "                      d=None,           # để None nếu muốn tự động xác định d\n",
    "                      seasonal=False,   # đặt True nếu chuỗi thời gian là mùa vụ\n",
    "                      stepwise=True,    # sử dụng phương pháp stepwise để tìm mô hình tối ưu\n",
    "                      information_criterion='aic',  # sử dụng AIC để tìm mô hình tốt nhất\n",
    "                      trace=True,       # in ra các bước tìm kiếm\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      random_state=42)        # số lượng mô hình khác nhau để thử\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c09c2-713d-4bfe-8462-0a7faa4e98ce",
   "metadata": {},
   "source": [
    "### 7. Khởi tạo và huấn luyện mô hình ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e9db4-8851-4161-9cbd-24937f12c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo và train mô hình\n",
    "model = ARIMA(y_train_diff, order=stepwise_fit.order)  # ARIMA(1,0,1)\n",
    "\n",
    "fit_model = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c278fe-8dc3-45b6-b93e-5b0c3509ea2d",
   "metadata": {},
   "source": [
    "### 7. Dự đoán và tính toán các độ đo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584651e-fcc8-4115-ab8a-6ff1fb6e6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "predictions_diff = fit_model.forecast(steps=test_data.shape[0])\n",
    "\n",
    "# Khôi phục giá trị gốc từ sai phân (nếu đã thực hiện sai phân)\n",
    "if adfuller(y_train)[1] > 0.05:\n",
    "    predictions = y_train.iloc[-1] + predictions_diff.cumsum()\n",
    "else:\n",
    "    predictions = predictions_diff\n",
    "\n",
    "y_true = y_test.values\n",
    "y_pred = predictions  # Sử dụng giá trị đã được khôi phục từ sai phân\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred) * 100 \n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# R-squared (R²)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}%\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd817ba-8e74-447c-b69f-d67e08ee382c",
   "metadata": {},
   "source": [
    "### 8. Biểu đồ dự đoán của mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402f853-1887-4f9b-8a74-fbfca47008e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6), dpi=150)\n",
    "\n",
    "# Vẽ dữ liệu huấn luyện\n",
    "plt.plot(train_data.index, y_train.values, color='black', lw=2)\n",
    "\n",
    "# Vẽ dữ liệu thực tế của tập kiểm tra\n",
    "plt.plot(test_data.index, y_test, color='blue', lw=2)\n",
    "\n",
    "# Vẽ dữ liệu dự đoán từ mô hình ARIMA\n",
    "plt.plot(test_data.index, predictions, label='Dữ liệu dự đoán', color='red')\n",
    "\n",
    "# Tiêu đề và nhãn\n",
    "plt.title(f'Hiệu suất mô hình dự đoán giá vàng với ARIMA{stepwise_fit.order}', fontsize=15)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price', fontsize=12)\n",
    "\n",
    "# Chú thích\n",
    "plt.legend(['Dữ liệu huấn luyện', 'Dữ liệu thực tế', 'Dữ liệu dự đoán'], prop={'size': 15})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (lab-data-mining)",
   "language": "python",
   "name": "lab-data-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
